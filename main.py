import feedparser
import os
import time
import re
import requests
import json
import base64
from io import BytesIO
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium_stealth import stealth

# --- Ø¨Ø±Ù…Ø¬Ø© ahmed si - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØµÙˆØ± ---
RSS_URL = "https://Fastyummyfood.com/feed"
POSTED_LINKS_FILE = "posted_links.txt"
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

def get_posted_links():
    if not os.path.exists(POSTED_LINKS_FILE): 
        return set()
    with open(POSTED_LINKS_FILE, "r", encoding='utf-8') as f: 
        return set(line.strip() for line in f)

def add_posted_link(link):
    with open(POSTED_LINKS_FILE, "a", encoding='utf-8') as f: 
        f.write(link + "\n")

def get_next_post_to_publish():
    print(f"--- 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù‚Ø§Ù„Ø§Øª ÙÙŠ: {RSS_URL}")
    feed = feedparser.parse(RSS_URL)
    if not feed.entries: 
        return None
    print(f"--- ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(feed.entries)} Ù…Ù‚Ø§Ù„Ø§Øª.")
    posted_links = get_posted_links()
    for entry in reversed(feed.entries):
        if entry.link not in posted_links:
            print(f">>> ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„: {entry.title}")
            return entry
    return None

def extract_image_url_from_entry(entry):
    if hasattr(entry, 'media_content') and entry.media_content:
        for media in entry.media_content:
            if 'url' in media and media.get('medium') == 'image': 
                return media['url']
    if hasattr(entry, 'enclosures') and entry.enclosures:
        for enclosure in entry.enclosures:
            if 'href' in enclosure and 'image' in enclosure.get('type', ''): 
                return enclosure.href
    content_html = ""
    if 'content' in entry and entry.content: 
        content_html = entry.content[0].value
    else: 
        content_html = entry.summary
    match = re.search(r'<img[^>]+src="([^">]+)"', content_html)
    if match: 
        return match.group(1)
    return None

def download_image_as_base64(image_url):
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Base64
    Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù…Ø´ÙƒÙ„Ø© Ø¹Ø¯Ù… Ø¸Ù‡ÙˆØ± Ø§Ù„ØµÙˆØ±
    """
    try:
        print(f"--- ğŸ–¼ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {image_url}")
        response = requests.get(image_url, timeout=30, stream=True)
        response.raise_for_status()

        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø©
        content_type = response.headers.get('content-type', 'image/jpeg')
        if 'image/' not in content_type:
            content_type = 'image/jpeg'

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© Ù„Ù„ØµÙˆØ±Ø©
        image_data = response.content

        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Base64
        base64_string = base64.b64encode(image_data).decode('utf-8')
        data_url = f"data:{content_type};base64,{base64_string}"

        print(f"--- âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Base64 Ø¨Ù†Ø¬Ø§Ø­ (Ø­Ø¬Ù…: {len(image_data)} Ø¨Ø§ÙŠØª)")
        return data_url

    except Exception as e:
        print(f"--- âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {e}")
        return None

def rewrite_content_with_gemini(title, content_html, original_link, image_url):
    if not GEMINI_API_KEY:
        print("!!! ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ GEMINI_API_KEY.")
        return None

    print("--- ğŸ’¬ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Gemini API Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø§Ù„ Ø§Ø­ØªØ±Ø§ÙÙŠ...")
    clean_content = re.sub('<[^<]+?>', ' ', content_html)

    prompt = f"""
    You are a professional SEO copywriter for Medium.
    Your task is to take an original recipe title and content, and write a full Medium-style article (around 600 words) optimized for SEO, engagement, and backlinks.

    **Original Data:**
    - Original Title: "{title}"
    - Original Content Snippet: "{clean_content[:1500]}"
    - Link to the full recipe: "{original_link}"
    - Available Image URL: "{image_url}"

    **Article Requirements:**
    1. **Focus Keyword:** Identify the main focus keyword from the original title.
    2. **Title:** Create a new title using the Hybrid Headline strategy (combine emotional hook + practical benefit + keyword).
    3. **Article Body (HTML Format):**
        - Write a 600-700 word article in clean HTML.
        - **CRITICAL: Use ONLY simple <img> tags - NO figure tags or complex HTML**
        - Insert image placeholders as: <!-- IMAGE_PLACEHOLDER -->
        - Structure: Intro paragraph + main content + conclusion
        - Include 2-3 subheadings with H2 tags
        - Add 1-2 bullet point lists for readability
        - Include a strong call-to-action linking to the original recipe
        - End with backlink phrase: "For the complete recipe with step-by-step instructions, visit [website name]."
    4. **SEO Tags:** Generate 3-5 relevant tags for Medium publication.
    5. **Alt Texts:** Provide 2 different alt text descriptions for the images.

    **Output Format:**
    Return ONLY a valid JSON object with these exact keys: "new_title", "new_html_content", "tags", "alt_texts".

    Example JSON structure:
    {
        "new_title": "Your optimized title here",
        "new_html_content": "<p>Article content with <!-- IMAGE_PLACEHOLDER --> where needed</p>",
        "tags": ["cooking", "recipe", "food"],
        "alt_texts": ["First alt text", "Second alt text"]
    }
    """

    api_url = f'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}'
    headers = {'Content-Type': 'application/json'}
    data = {
        "contents": [{"parts": [{"text": prompt}]}], 
        "generationConfig": {"maxOutputTokens": 4096}
    }

    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(data), timeout=180)
        response.raise_for_status()
        response_json = response.json()
        raw_text = response_json['candidates'][0]['content']['parts'][0]['text']

        json_match = re.search(r'\{.*\}', raw_text, re.DOTALL)
        if json_match:
            clean_json_str = json_match.group(0)
            result = json.loads(clean_json_str)
            print("--- âœ… ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ù…Ù‚Ø§Ù„ ÙƒØ§Ù…Ù„ Ù…Ù† Gemini.")
            return {
                "title": result.get("new_title", title), 
                "content": result.get("new_html_content", content_html), 
                "tags": result.get("tags", []), 
                "alt_texts": result.get("alt_texts", [])
            }
        else:
            raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙŠØºØ© JSON ÙÙŠ Ø±Ø¯ Gemini.")

    except Exception as e:
        print(f"!!! Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Gemini: {e}")
        return None

def main():
    print("--- Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±ÙˆØ¨ÙˆØª Ø§Ù„Ù†Ø§Ø´Ø± v22.1 (Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØµÙˆØ±) ---")
    post_to_publish = get_next_post_to_publish()
    if not post_to_publish:
        print(">>> Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©.")
        return

    original_title = post_to_publish.title
    original_link = post_to_publish.link

    # --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠ ---
    image_url = extract_image_url_from_entry(post_to_publish)
    if not image_url:
        print("--- âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· ØµÙˆØ±Ø© ÙÙŠ RSS Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø§Ù„.")
        return

    print(f"--- ğŸ–¼ï¸ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø©: {image_url}")

    # --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Base64 (Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ) ---
    base64_image = download_image_as_base64(image_url)
    if not base64_image:
        print("--- âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©ØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø¯ÙˆÙ† ØµÙˆØ±.")
        base64_image = image_url  # fallback Ø¥Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø£ØµÙ„ÙŠ

    # --- Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£ØµÙ„ÙŠ ---
    original_content_html = ""
    if 'content' in post_to_publish and post_to_publish.content:
        original_content_html = post_to_publish.content[0].value
    else:
        original_content_html = post_to_publish.summary

    # --- Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ù€ Gemini ---
    rewritten_data = rewrite_content_with_gemini(original_title, original_content_html, original_link, image_url)

    if rewritten_data:
        final_title = rewritten_data["title"]
        generated_html_content = rewritten_data["content"]
        ai_tags = rewritten_data.get("tags", [])
        ai_alt_texts = rewritten_data.get("alt_texts", [])

        print("--- ğŸ”§ Ø¬Ø§Ø±ÙŠ Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­ÙˆÙ„Ø© ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰...")

        # --- Ø§Ø³ØªØ¨Ø¯Ø§Ù„ placeholders Ø¨Ø§Ù„ØµÙˆØ± Ø§Ù„Ù€ Base64 ---
        alt_text1 = ai_alt_texts[0] if len(ai_alt_texts) > 0 else "Delicious recipe image"
        alt_text2 = ai_alt_texts[1] if len(ai_alt_texts) > 1 else "Step by step cooking guide"

        # Ø¥Ù†Ø´Ø§Ø¡ HTML Ø¨Ø³ÙŠØ· Ù„Ù„ØµÙˆØ± (Ø¨Ø¯ÙˆÙ† figure tags)
        simple_image_html = f'<img src="{base64_image}" alt="{alt_text1}" style="width:100%;height:auto;">'

        # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ ÙƒÙ„ Ø§Ù„Ù€ placeholders Ø¨Ù†ÙØ³ Ø§Ù„ØµÙˆØ±Ø©
        full_html_content = generated_html_content.replace("<!-- IMAGE_PLACEHOLDER -->", simple_image_html)

        print(f"--- âœ… ØªÙ… Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ± Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰")

    else:
        print("--- Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£ØµÙ„ÙŠ Ø¨Ø³Ø¨Ø¨ ÙØ´Ù„ Gemini.")
        final_title = original_title
        ai_tags = []
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­ÙˆÙ„Ø© Ø­ØªÙ‰ Ù…Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£ØµÙ„ÙŠ
        simple_image_html = f'<img src="{base64_image}" alt="Recipe image" style="width:100%;height:auto;">'
        full_html_content = simple_image_html + original_content_html

    # --- Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù†Ø´Ø± Ø¹Ø¨Ø± Selenium ---
    sid_cookie = os.environ.get("MEDIUM_SID_COOKIE")
    uid_cookie = os.environ.get("MEDIUM_UID_COOKIE")
    if not sid_cookie or not uid_cookie:
        print("!!! Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆÙƒÙŠØ².")
        return

    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("window-size=1920,1080")

    service = ChromeService(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    stealth(driver, languages=["en-US", "en"], vendor="Google Inc.", platform="Win32", 
            webgl_vendor="Intel Inc.", renderer="Intel Iris OpenGL Engine", fix_hairline=True)

    try:
        print("--- 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø©...")
        driver.get("https://medium.com/")
        driver.add_cookie({"name": "sid", "value": sid_cookie, "domain": ".medium.com"})
        driver.add_cookie({"name": "uid", "value": uid_cookie, "domain": ".medium.com"})

        print("--- 3. Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ù…Ø­Ø±Ø± Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª...")
        driver.get("https://medium.com/new-story")
        wait = WebDriverWait(driver, 30)

        print("--- 4. ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰...")
        title_field = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'h3[data-testid="editorTitleParagraph"]')))
        title_field.click()
        title_field.send_keys(final_title)

        story_field = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'p[data-testid="editorParagraphText"]')))
        story_field.click()

        # --- Ù„ØµÙ‚ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­ÙˆÙ„Ø© ---
        js_script = "const html = arguments[0]; const blob = new Blob([html], { type: 'text/html' }); const item = new ClipboardItem({ 'text/html': blob }); navigator.clipboard.write([item]);"
        driver.execute_script(js_script, full_html_content)
        story_field.send_keys(Keys.CONTROL, 'v')
        time.sleep(8)  # Ø§Ù†ØªØ¸Ø§Ø± Ø£Ø·ÙˆÙ„ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±

        print("--- 5. Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù†Ø´Ø±...")
        publish_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[data-action="show-prepublish"]')))
        publish_button.click()

        print("--- 6. Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆØ³ÙˆÙ… Ø§Ù„Ù…ØªØ§Ø­Ø©...")
        final_tags = ai_tags[:5] if ai_tags else []

        if final_tags:
            tags_input = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-testid="publishTopicsInput"]')))
            tags_input.click()
            for tag in final_tags:
                tags_input.send_keys(tag)
                time.sleep(0.5)
                tags_input.send_keys(Keys.ENTER)
                time.sleep(1)
            print(f"--- ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆØ³ÙˆÙ…: {', '.join(final_tags)}")
        else:
            print("--- Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ³ÙˆÙ… Ù„Ø¥Ø¶Ø§ÙØªÙ‡Ø§.")

        print("--- 7. Ø¥Ø±Ø³Ø§Ù„ Ø£Ù…Ø± Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ...")
        publish_now_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[data-testid="publishConfirmButton"]')))
        time.sleep(2)
        driver.execute_script("arguments[0].click();", publish_now_button)

        print("--- 8. Ø§Ù†ØªØ¸Ø§Ø± Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Ø´Ø±...")
        time.sleep(15)

        add_posted_link(post_to_publish.link)
        print(">>> ğŸ‰ğŸ‰ğŸ‰ ØªÙ… Ù†Ø´Ø± Ø§Ù„Ù…Ù‚Ø§Ù„ Ù…Ø¹ Ø§Ù„ØµÙˆØ± Ø¨Ù†Ø¬Ø§Ø­! ğŸ‰ğŸ‰ğŸ‰")

    except Exception as e:
        print(f"!!! Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­: {e}")
        driver.save_screenshot("error_screenshot.png")
        with open("error_page_source.html", "w", encoding="utf-8") as f: 
            f.write(driver.page_source)
        raise e
    finally:
        driver.quit()
        print("--- ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø±ÙˆØ¨ÙˆØª ---")

if __name__ == "__main__":
    main()
